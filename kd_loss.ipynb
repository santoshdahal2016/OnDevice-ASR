{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermidiate KL: tensor([26.2418, 31.6345, 22.5171, 18.8390, 30.3760, 30.2018, 25.5498, 29.3478],\n",
      "       grad_fn=<MulBackward0>)\n",
      "Offline KL: 26.83846092224121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dump = torch.load(\"rnnt_joint_dump.pt\", map_location=\"cpu\", weights_only=True )\n",
    "\n",
    "tj = dump[\"teacher_joint\"]          # (B,T,U,V)\n",
    "sj = dump[\"student_joint\"]\n",
    "\n",
    "# e.g. compute perâ€‘position softmax\n",
    "T = 20\n",
    "teacher_p = torch.softmax(tj / T, dim=-1)\n",
    "student_lp = torch.log_softmax(sj / T, dim=-1)\n",
    "kl_intermidiate = torch.nn.functional.kl_div(student_lp, teacher_p,\n",
    "                                reduction=\"none\").sum(-1)\n",
    "\n",
    "kl = kl_intermidiate.mean(dim=(1, 2)) * (T**2)\n",
    "\n",
    "offline_kl = kl.mean()   \n",
    "\n",
    "print(\"Intermidiate KL:\", kl)\n",
    "print(\"Offline KL:\", offline_kl.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6641, 0.7880, 0.9131,  ..., 0.2978, 0.2841, 0.2924],\n",
      "         [0.7909, 0.8251, 0.9037,  ..., 0.3590, 0.3458, 0.3526],\n",
      "         [0.9411, 0.8119, 0.8889,  ..., 0.3997, 0.3854, 0.3902],\n",
      "         ...,\n",
      "         [0.4873, 0.7092, 0.7697,  ..., 0.2168, 0.2098, 0.2115],\n",
      "         [0.4885, 0.7065, 0.7717,  ..., 0.2171, 0.2104, 0.2105],\n",
      "         [0.4818, 0.7115, 0.7699,  ..., 0.2136, 0.2061, 0.2083]],\n",
      "\n",
      "        [[0.7898, 0.5736, 0.4656,  ..., 0.4037, 1.3118, 0.4570],\n",
      "         [1.2515, 0.8188, 0.5717,  ..., 0.4686, 1.4619, 0.7413],\n",
      "         [2.1305, 2.3063, 1.8055,  ..., 0.9677, 1.7195, 1.8705],\n",
      "         ...,\n",
      "         [0.4887, 0.6136, 0.4712,  ..., 0.3478, 1.1583, 0.3914],\n",
      "         [0.4889, 0.6123, 0.4704,  ..., 0.3464, 1.1613, 0.3917],\n",
      "         [0.4823, 0.6078, 0.4667,  ..., 0.3444, 1.1644, 0.3850]],\n",
      "\n",
      "        [[0.3498, 0.2992, 0.2607,  ..., 0.5040, 0.8839, 0.2336],\n",
      "         [0.3362, 0.2921, 0.2907,  ..., 0.5095, 0.9556, 0.2789],\n",
      "         [0.3356, 0.3014, 0.3032,  ..., 0.5148, 0.9709, 0.3141],\n",
      "         ...,\n",
      "         [0.9091, 0.8283, 0.8130,  ..., 0.8964, 0.5435, 0.7542],\n",
      "         [0.8555, 0.7702, 0.7502,  ..., 0.8010, 0.5676, 0.6782],\n",
      "         [0.7204, 0.6343, 0.5380,  ..., 0.6879, 0.8240, 0.9298]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9123, 0.7717, 0.4577,  ..., 0.6223, 0.5494, 0.2633],\n",
      "         [1.3205, 0.8716, 0.6558,  ..., 0.9015, 0.8387, 0.3808],\n",
      "         [1.9440, 0.9576, 1.3780,  ..., 1.3536, 1.5475, 0.7218],\n",
      "         ...,\n",
      "         [0.4786, 0.5726, 0.3863,  ..., 0.4085, 0.4839, 0.1280],\n",
      "         [0.4870, 0.5965, 0.3929,  ..., 0.4353, 0.4926, 0.1412],\n",
      "         [0.4820, 0.6008, 0.3877,  ..., 0.4306, 0.4868, 0.1372]],\n",
      "\n",
      "        [[0.5560, 0.3804, 1.4573,  ..., 0.2773, 0.2805, 0.2817],\n",
      "         [0.5913, 0.3682, 1.5595,  ..., 0.3581, 0.3619, 0.3624],\n",
      "         [0.8499, 0.5687, 1.4904,  ..., 0.4660, 0.4694, 0.4685],\n",
      "         ...,\n",
      "         [0.4876, 0.4471, 1.5643,  ..., 0.2331, 0.2357, 0.2369],\n",
      "         [0.4898, 0.4459, 1.5668,  ..., 0.2338, 0.2341, 0.2361],\n",
      "         [0.4811, 0.4395, 1.5788,  ..., 0.2319, 0.2318, 0.2340]],\n",
      "\n",
      "        [[0.9690, 0.4870, 0.4906,  ..., 0.2716, 0.2894, 0.3413],\n",
      "         [1.4815, 0.5946, 0.6591,  ..., 0.3748, 0.4135, 0.5146],\n",
      "         [2.0764, 0.8949, 0.9286,  ..., 0.5590, 0.5637, 0.7257],\n",
      "         ...,\n",
      "         [1.5136, 0.9277, 0.9276,  ..., 0.6616, 0.5886, 0.7164],\n",
      "         [1.8151, 1.3901, 1.3845,  ..., 1.0153, 0.8568, 1.0340],\n",
      "         [1.4093, 0.7542, 0.8657,  ..., 0.4898, 0.4757, 0.5771]]],\n",
      "       grad_fn=<SumBackward1>)\n",
      "KL per sample: tensor([1.9036, 1.9633, 1.4564, 1.2922, 2.0260, 2.1547, 1.9266, 2.2122],\n",
      "       grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "kl_pos = torch.nn.functional.kl_div(student_lp, teacher_p, reduction='none')  # (B, T, U, V)\n",
    "kl_sum = kl_pos.sum(-1)  # (B, T, U)\n",
    "\n",
    "print(kl_sum)\n",
    "\n",
    "kl_per_sample = kl_sum.mean(dim=(1, 2))  # (B,)\n",
    "print(\"KL per sample:\", kl_per_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
